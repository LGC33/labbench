{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging device states and test results to a database\n",
    "A number of tools are included in `labbench` to streamline acquisition of test data into a database. A couple of methods are\n",
    "\n",
    "* Automatically monitoring attributes in `state` and logging changes\n",
    "* Saving postprocessed data in the as a new column\n",
    "\n",
    "The data management supports automatic relational databasing. Common non-scalar data types (`pandas.DataFrame`, `numpy.array`, long strings, files generated outside of the data tree, etc.) are automatically stored relationally --- placed in folders and referred to in the database. Other data can be forced to be relational by dynamically generating relational databases on the fly.\n",
    "\n",
    "#### File conventions\n",
    "All labbench data save functionality is implemented in tables with [pandas](pandas.pydata.org) DataFrame backends. Here are database storage formats that are supported:\n",
    "\n",
    "| Format                            | File extension(s)              | Data management class | flag to [use record file format](http://ssm.ipages.nist.gov/labbench/labbench.html#labbench.managedata.StatesToRelationalTable.set_relational_file_format) | Comments |\n",
    "|:----------------------------------|:-------------------------------|:-----------------------|:------------------------|:----\n",
    "| [sqlite](sqlite.org)              | .db                            | [labbench.StatesToSQLite](http://ssm.ipages.nist.gov/labbench/labbench.html#labbench.managedata.StatesToSQLite) | 'sqlite' | Scales to larger databases than csv |\n",
    "| csv                               | .csv,.csv.gz,.csv.bz2,.csv.zip | [labbench.StatesToCSV](http://ssm.ipages.nist.gov/labbench/labbench.html#labbench.managedata.StatesToCSV)          |'csv'| Easy to inspect |\n",
    "\n",
    "Several formats are supported only as relational data (data stored in a file in the subdirectory instead of directly in the ). Certain types of data as values into the database manager automatically become relational data when you call the `append` method of the data manager:\n",
    "\n",
    "| Format                            | File extension(s)              | python type conversion | [set_record file format](http://ssm.ipages.nist.gov/labbench/labbench.html#labbench.managedata.StatesToRelationalTable.set_relational_file_format) flag | Comments |\n",
    "|:----------------------------------|:-------------------------------|:-----------------------|:------------------------|:----\n",
    "| [feather](github.com/wesm/feather)| .f                             | iterables of numbers and strings; pd.DataFrame | 'feather' | Python 3.x only\n",
    "| [json](http://www.json.org/)      | .json                          | iterables of numbers and strings; pd.DataFrame         | 'json' | |\n",
    "| csv                               | .csv | iterables of numbers and strings; pd.DataFrame         |'csv'| |\n",
    "| python [pickle](https://docs.python.org/3/library/pickle.html) | .pickle | any | 'pickle' | fallback if the chosen relational format fails |\n",
    "| text files     | .txt | string or bytes longer than `text_relational_min` | N/A | set `text_relational_min` when you instantiate the database manager\n",
    "| arbitrary files generated outside the file tree |     *             | strings containing filesystem path | N/A |\n",
    "\n",
    "In the following example, we will use an sqlite master database, and csv record files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "Here is a emulated \"dummy\" instrument. It has a few state settings similar to a simple power sensor. The state descriptors (`initiate_continuous`, `output_trigger`, etc.) are defined as local types, which means they don't trigger communication with any actual devices. The `fetch_trace` method generates a \"trace\" drawn from a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "import labbench as lb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class EmulatedInstrument(lb.EmulatedVISADevice):\n",
    "    ''' This \"instrument\" makes mock data and instrument states to\n",
    "        demonstrate we can show the process of setting\n",
    "        up a measurement.\n",
    "    '''\n",
    "    class state (lb.EmulatedVISADevice.state):\n",
    "        initiate_continuous = lb.Bool(command='INIT:CONT')\n",
    "        output_trigger      = lb.Bool(command='OUTP:TRIG')\n",
    "        sweep_aperture      = lb.Float(min=20e-6, max=200e-3,help='s')\n",
    "        frequency           = lb.Float(min=10e6, max=18e9,step=1e-3,help='Hz')\n",
    "\n",
    "    def trigger(self):\n",
    "        ''' This would tell the instrument to start a measurement\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def fetch_trace(self, N=1001):\n",
    "        ''' Generate N points of junk data as a pandas series.\n",
    "        '''\n",
    "        values = np.random.normal(size=N)\n",
    "        index = np.linspace(0,self.state.sweep_aperture,N)\n",
    "        series = pd.Series(values,index=index,name='voltage')\n",
    "        series.index.name = 'time'\n",
    "        return series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a loop to execute 100 test runs with two emulated instruments, and log the results with a relational SQLite database. I do a little setup to start:\n",
    "\n",
    "1. Define a couple of functions `inst1_trace` and `inst2_trace` that collect my data\n",
    "2. Instantiate 2 instruments, `inst1` and `inst2`\n",
    "3. Instantiate the logger with `lb.StatesToSQLite('test.db', 'state')`.\n",
    "   The arguments specify the name of the sqlite database file and the name of the table where the following will be stored: 1) the instrument state info will be stored, 2) locations of data files, and 3) any extra comments we add with `db.write()`.\n",
    "\n",
    "Remember that use of the `with` statement automatically connects to the instruments, and then ensures that the instruments are properly closed when we leave the `with` block (even if there is an exception)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\labbench\\data.py:841: UserWarning: set_nonscalar_file_type is deprecated; set when creating\n",
      "                         the database object instead with the nonscalar_output flag\n",
      "  the database object instead with the nonscalar_output flag''')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-384902b63f80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;31m# are also added corresponding to attributes inst1.state and inst2.state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             db.append(comments='trying for 1.21 GW to time travel',\n\u001b[1;32m---> 46\u001b[1;33m                       **data)\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Source\\labbench-github\\labbench\\data.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Source\\labbench-github\\labbench\\data.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    920\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    921\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 922\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmunge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    923\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m             \u001b[0mex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Source\\labbench-github\\labbench\\data.py\u001b[0m in \u001b[0;36mwrite_metadata\u001b[1;34m(self, name, key)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    420\u001b[0m                                          dtype=values.dtype, copy=False)\n\u001b[0;32m    421\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataFrame constructor not properly called!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "def inst1_trace ():\n",
    "    ''' Return a 1001-point trace\n",
    "    '''\n",
    "    inst1.trigger()\n",
    "    return inst1.fetch_trace(51)\n",
    "\n",
    "def inst2_trace ():\n",
    "    ''' This one returns only one point\n",
    "    '''\n",
    "    inst2.trigger()\n",
    "    return inst2.fetch_trace(1).values[0]\n",
    "    \n",
    "# Root directory of the database\n",
    "db_path = r'data'\n",
    "\n",
    "# Seed the data dictionary with some global data\n",
    "data = {'dut': 'DUT 15'}\n",
    "\n",
    "Nfreqs = 101\n",
    "\n",
    "with EmulatedInstrument()        as inst1,\\\n",
    "     EmulatedInstrument()        as inst2,\\\n",
    "     lb.StatesToSQLite(db_path, nonscalar_output='csv')  as db:\n",
    "        # Catch any changes in inst1.state and inst2.state\n",
    "        db.observe_states([inst1,inst2])  \n",
    "        \n",
    "        # Update inst1.state.sweep_aperture on each db.append\n",
    "        db.observe_states(inst1, always='sweep_aperture')\n",
    "        \n",
    "        # Store trace data in csv format\n",
    "        db.set_relational_file_format('csv')\n",
    "        \n",
    "        # Perform a frequency sweep. The frequency will be logged to the\n",
    "        # database, because we configured it to observe all state changes.\n",
    "        inst2.state.frequency = 5.8e9\n",
    "        for inst1.state.frequency in np.linspace(5.8e9, 5.9e9, Nfreqs):                    \n",
    "            # Collect \"test data\" by concurrently calling\n",
    "            # inst1_trace and inst2_trace\n",
    "            data.update(lb.concurrently(inst1_trace, inst2_trace))\n",
    "\n",
    "            # Append the new data as a row to the database.\n",
    "            # Each key is a column in the database (which will be added\n",
    "            # dynamically to the database if needed). More keys and values\n",
    "            # are also added corresponding to attributes inst1.state and inst2.state\n",
    "            db.append(comments='trying for 1.21 GW to time travel',\n",
    "                      **data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading and exploring the data\n",
    "The master database is now populated with the test results and subdirectories are populated with trace data. `labbench` provides the function `read` as a shortcut to load the sqlite database into a pandas dataframe. Each state is a column in the database. The logger creates columns named as a combination of the device name ('inst1') and name of the corresponding device state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "master = lb.read(f'{db_path}/master.db')\n",
    "master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pandas DataFrame object. There is extensive information about how to use dataframes [on the pandas website](http://pandas.pydata.org/pandas-docs/stable/). Suppose we want to bring in the data from the traces, which are in a collection of waveform files specified under the `inst1_trace` column. The function `labbench.expand` serves to flatten the database with respect to data files that were generated on each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = lb.read_relational(f'{db_path}/master.db', 'inst1_trace', ['dut', 'inst1_frequency'])\n",
    "waveforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can manipulate the results to look for meaningful information in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set(context='notebook', style='ticks', font_scale=1.5) # Theme stuff\n",
    "\n",
    "waveforms.plot(x='inst1_frequency',y='inst1_trace_voltage',kind='hexbin')\n",
    "xlabel('Frequency (Hz)')\n",
    "ylabel('Voltage (arb units)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
